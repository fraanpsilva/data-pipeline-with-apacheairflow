[2023-02-10 14:23:34,862] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:23:34,864] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:23:34,864] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:23:34,865] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:23:34,865] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:23:34,868] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:23:34,870] {standard_task_runner.py:52} INFO - Started process 33820 to run task
[2023-02-10 14:23:34,873] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '73', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpfi6wow9s', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpvqpf1l6t']
[2023-02-10 14:23:34,873] {standard_task_runner.py:80} INFO - Job 73: Subtask cria_pasta
[2023-02-10 14:23:34,889] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:23:34,906] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1451, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1555, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2212, in render_templates
    rendered_task = self.task.render_template_fields(context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 1185, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 344, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 387, in render_template
    template = jinja_env.from_string(value)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line -1, in template
jinja2.exceptions.TemplateSyntaxError: unexpected end of template, expected ','.
[2023-02-10 14:23:34,909] {taskinstance.py:1395} INFO - Marking task as FAILED. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T142334, end_date=20230210T142334
[2023-02-10 14:23:34,912] {standard_task_runner.py:92} ERROR - Failed to execute job 73 for task cria_pasta (unexpected end of template, expected ','.; 33820)
[2023-02-10 14:23:34,935] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-02-10 14:23:34,945] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-02-10 14:28:51,073] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:28:51,075] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:28:51,075] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:28:51,075] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:28:51,075] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:28:51,078] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:28:51,080] {standard_task_runner.py:52} INFO - Started process 34601 to run task
[2023-02-10 14:28:51,083] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpewet98dk', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpsqk3fmz6']
[2023-02-10 14:28:51,084] {standard_task_runner.py:80} INFO - Job 61: Subtask cria_pasta
[2023-02-10 14:28:51,099] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:28:51,115] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 14:28:51,116] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 14:28:51,116] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06T00:00:00+00:00" ']
[2023-02-10 14:28:51,119] {subprocess.py:85} INFO - Output:
[2023-02-10 14:28:51,122] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 14:28:51,130] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T142851, end_date=20230210T142851
[2023-02-10 14:28:51,145] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 14:28:51,153] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-02-10 14:31:50,111] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:31:50,113] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:31:50,113] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:31:50,113] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:31:50,113] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:31:50,117] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:31:50,118] {standard_task_runner.py:52} INFO - Started process 35093 to run task
[2023-02-10 14:31:50,121] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '59', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmp7ezikrdw', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpeguon9c8']
[2023-02-10 14:31:50,122] {standard_task_runner.py:80} INFO - Job 59: Subtask cria_pasta
[2023-02-10 14:31:50,137] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:31:50,145] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1451, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1555, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2212, in render_templates
    rendered_task = self.task.render_template_fields(context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 1185, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 344, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 387, in render_template
    template = jinja_env.from_string(value)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line -1, in template
jinja2.exceptions.TemplateSyntaxError: unexpected end of template, expected ','.
[2023-02-10 14:31:50,148] {taskinstance.py:1395} INFO - Marking task as FAILED. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T143150, end_date=20230210T143150
[2023-02-10 14:31:50,150] {standard_task_runner.py:92} ERROR - Failed to execute job 59 for task cria_pasta (unexpected end of template, expected ','.; 35093)
[2023-02-10 14:31:50,152] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-02-10 14:31:50,162] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-02-10 14:46:31,765] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:46:31,767] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:46:31,767] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:46:31,767] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:46:31,767] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:46:31,771] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:46:31,772] {standard_task_runner.py:52} INFO - Started process 36870 to run task
[2023-02-10 14:46:31,775] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpduzf8x_0', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmppy7fk8gj']
[2023-02-10 14:46:31,775] {standard_task_runner.py:80} INFO - Job 61: Subtask cria_pasta
[2023-02-10 14:46:31,791] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:46:31,800] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1451, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1555, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2212, in render_templates
    rendered_task = self.task.render_template_fields(context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 1185, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 344, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 391, in render_template
    return render_template_to_string(template, context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/utils/helpers.py", line 296, in render_template_to_string
    return render_template(template, context, native=False)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/utils/helpers.py", line 291, in render_template
    return "".join(nodes)
  File "<template>", line 13, in root
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/runtime.py", line 753, in __getattr__
    return self._fail_with_undefined_error()
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/runtime.py", line 747, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'pendulum.datetime.DateTime object' has no attribute 'pendulum'
[2023-02-10 14:46:31,802] {taskinstance.py:1395} INFO - Marking task as FAILED. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T144631, end_date=20230210T144631
[2023-02-10 14:46:31,805] {standard_task_runner.py:92} ERROR - Failed to execute job 61 for task cria_pasta ('pendulum.datetime.DateTime object' has no attribute 'pendulum'; 36870)
[2023-02-10 14:46:31,834] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-02-10 14:46:31,841] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-02-10 14:48:48,772] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:48:48,774] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:48:48,774] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:48:48,774] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:48:48,774] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:48:48,778] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:48:48,780] {standard_task_runner.py:52} INFO - Started process 37249 to run task
[2023-02-10 14:48:48,782] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '63', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpac9am_jg', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmp44obg3mi']
[2023-02-10 14:48:48,783] {standard_task_runner.py:80} INFO - Job 63: Subtask cria_pasta
[2023-02-10 14:48:48,802] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:48:48,814] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1451, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 1555, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 2212, in render_templates
    rendered_task = self.task.render_template_fields(context)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 1185, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 344, in _do_render_template_fields
    rendered_content = self.render_template(
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/airflow/models/abstractoperator.py", line 387, in render_template
    template = jinja_env.from_string(value)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/venv/lib/python3.10/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line -1, in template
jinja2.exceptions.TemplateSyntaxError: unexpected end of template, expected ','.
[2023-02-10 14:48:48,816] {taskinstance.py:1395} INFO - Marking task as FAILED. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T144848, end_date=20230210T144848
[2023-02-10 14:48:48,819] {standard_task_runner.py:92} ERROR - Failed to execute job 63 for task cria_pasta (unexpected end of template, expected ','.; 37249)
[2023-02-10 14:48:48,843] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-02-10 14:48:48,852] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-02-10 14:53:09,335] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:53:09,337] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:53:09,337] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:53:09,337] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:53:09,337] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:53:09,341] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:53:09,344] {standard_task_runner.py:52} INFO - Started process 37948 to run task
[2023-02-10 14:53:09,347] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '65', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpd2zi698y', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpa2erzef7']
[2023-02-10 14:53:09,348] {standard_task_runner.py:80} INFO - Job 65: Subtask cria_pasta
[2023-02-10 14:53:09,369] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:53:09,387] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 14:53:09,388] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 14:53:09,388] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06T00:00:00+00:00"']
[2023-02-10 14:53:09,393] {subprocess.py:85} INFO - Output:
[2023-02-10 14:53:09,398] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 14:53:09,407] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T145309, end_date=20230210T145309
[2023-02-10 14:53:09,453] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 14:53:09,461] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-02-10 14:54:42,437] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:54:42,440] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:54:42,440] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:54:42,440] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:54:42,440] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:54:42,444] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:54:42,446] {standard_task_runner.py:52} INFO - Started process 38278 to run task
[2023-02-10 14:54:42,448] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '71', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpak_m3c_8', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpfufy2ihi']
[2023-02-10 14:54:42,449] {standard_task_runner.py:80} INFO - Job 71: Subtask cria_pasta
[2023-02-10 14:54:42,467] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:54:42,484] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 14:54:42,484] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 14:54:42,484] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06T00:00:00+00:00"']
[2023-02-10 14:54:42,488] {subprocess.py:85} INFO - Output:
[2023-02-10 14:54:42,491] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 14:54:42,500] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T145442, end_date=20230210T145442
[2023-02-10 14:54:42,511] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 14:54:42,519] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-02-10 14:58:57,598] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:58:57,601] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 14:58:57,601] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:58:57,601] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 14:58:57,601] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 14:58:57,605] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 14:58:57,606] {standard_task_runner.py:52} INFO - Started process 38909 to run task
[2023-02-10 14:58:57,609] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '73', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpc3b3cs_t', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpj0awv3eb']
[2023-02-10 14:58:57,609] {standard_task_runner.py:80} INFO - Job 73: Subtask cria_pasta
[2023-02-10 14:58:57,625] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 14:58:57,640] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 14:58:57,641] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 14:58:57,641] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06T00:00:00+00:00"']
[2023-02-10 14:58:57,647] {subprocess.py:85} INFO - Output:
[2023-02-10 14:58:57,653] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 14:58:57,663] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T145857, end_date=20230210T145857
[2023-02-10 14:58:57,671] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 14:58:57,681] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-02-10 17:29:29,946] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:29:29,949] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:29:29,949] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:29:29,949] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 17:29:29,949] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:29:29,952] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 17:29:29,954] {standard_task_runner.py:52} INFO - Started process 55377 to run task
[2023-02-10 17:29:29,956] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '111', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpftlvq3_t', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpswu0qjb9']
[2023-02-10 17:29:29,957] {standard_task_runner.py:80} INFO - Job 111: Subtask cria_pasta
[2023-02-10 17:29:29,972] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 17:29:29,989] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 17:29:29,989] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 17:29:29,990] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06"']
[2023-02-10 17:29:29,994] {subprocess.py:85} INFO - Output:
[2023-02-10 17:29:29,997] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 17:29:30,004] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T172929, end_date=20230210T172930
[2023-02-10 17:29:30,019] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 17:29:30,027] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-02-10 17:33:31,859] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:33:31,862] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:33:31,862] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:33:31,862] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 17:33:31,862] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:33:31,866] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 17:33:31,867] {standard_task_runner.py:52} INFO - Started process 55954 to run task
[2023-02-10 17:33:31,870] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpefroa5uq', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmp33jmcy_7']
[2023-02-10 17:33:31,871] {standard_task_runner.py:80} INFO - Job 127: Subtask cria_pasta
[2023-02-10 17:33:31,887] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 17:33:31,903] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 17:33:31,904] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 17:33:31,904] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06"']
[2023-02-10 17:33:31,912] {subprocess.py:85} INFO - Output:
[2023-02-10 17:33:31,916] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 17:33:31,926] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T173331, end_date=20230210T173331
[2023-02-10 17:33:31,975] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 17:33:31,987] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-02-10 17:35:53,413] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:35:53,416] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:35:53,416] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:35:53,416] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 17:35:53,416] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:35:53,420] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 17:35:53,422] {standard_task_runner.py:52} INFO - Started process 56275 to run task
[2023-02-10 17:35:53,425] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '121', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmp1ug88hbq', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpywrij03c']
[2023-02-10 17:35:53,426] {standard_task_runner.py:80} INFO - Job 121: Subtask cria_pasta
[2023-02-10 17:35:53,445] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 17:35:53,464] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 17:35:53,465] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 17:35:53,465] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06"']
[2023-02-10 17:35:53,469] {subprocess.py:85} INFO - Output:
[2023-02-10 17:35:53,473] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 17:35:53,481] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T173553, end_date=20230210T173553
[2023-02-10 17:35:53,524] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 17:35:53,534] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-02-10 17:46:50,585] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:46:50,587] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:46:50,587] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:46:50,587] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 17:46:50,587] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:46:50,591] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 17:46:50,593] {standard_task_runner.py:52} INFO - Started process 57686 to run task
[2023-02-10 17:46:50,595] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '123', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpe9v2y73j', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmp1i771_sv']
[2023-02-10 17:46:50,596] {standard_task_runner.py:80} INFO - Job 123: Subtask cria_pasta
[2023-02-10 17:46:50,611] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 17:46:50,629] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 17:46:50,629] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 17:46:50,630] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06"']
[2023-02-10 17:46:50,633] {subprocess.py:85} INFO - Output:
[2023-02-10 17:46:50,636] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 17:46:50,644] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T174650, end_date=20230210T174650
[2023-02-10 17:46:50,656] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 17:46:50,664] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2023-02-10 17:56:11,931] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:56:11,933] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [queued]>
[2023-02-10 17:56:11,933] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:56:11,933] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2023-02-10 17:56:11,933] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2023-02-10 17:56:11,937] {taskinstance.py:1377} INFO - Executing <Task(BashOperator): cria_pasta> on 2023-01-30 00:00:00+00:00
[2023-02-10 17:56:11,939] {standard_task_runner.py:52} INFO - Started process 59050 to run task
[2023-02-10 17:56:11,941] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'dados_climaticos', 'cria_pasta', 'scheduled__2023-01-30T00:00:00+00:00', '--job-id', '125', '--raw', '--subdir', 'DAGS_FOLDER/dados_climaticos.py', '--cfg-path', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmpma7e_cc_', '--error-file', '/var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T/tmp9c1or48o']
[2023-02-10 17:56:11,942] {standard_task_runner.py:80} INFO - Job 125: Subtask cria_pasta
[2023-02-10 17:56:11,961] {task_command.py:370} INFO - Running <TaskInstance: dados_climaticos.cria_pasta scheduled__2023-01-30T00:00:00+00:00 [running]> on host airdefrancilene.lan
[2023-02-10 17:56:11,979] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=dados_climaticos
AIRFLOW_CTX_TASK_ID=cria_pasta
AIRFLOW_CTX_EXECUTION_DATE=2023-01-30T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-30T00:00:00+00:00
[2023-02-10 17:56:11,980] {subprocess.py:62} INFO - Tmp dir root location: 
 /var/folders/b_/44w2czd50d77jsslrsmc4_sc0000gn/T
[2023-02-10 17:56:11,980] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'mkdir -p  "/Users/francilenesilva/Documents/data-engineer/apache-airflow/orquestrando-pipeline1/data-pipeline/airflow-alura/semana=2023-02-06"']
[2023-02-10 17:56:11,985] {subprocess.py:85} INFO - Output:
[2023-02-10 17:56:11,989] {subprocess.py:96} INFO - Command exited with return code 0
[2023-02-10 17:56:11,999] {taskinstance.py:1395} INFO - Marking task as SUCCESS. dag_id=dados_climaticos, task_id=cria_pasta, execution_date=20230130T000000, start_date=20230210T175611, end_date=20230210T175611
[2023-02-10 17:56:12,041] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-02-10 17:56:12,051] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
